{
  "access_type": "PRIVATE",
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "YouTubeCommentsComponent",
            "id": "YouTubeCommentsComponent-GFgM6",
            "name": "comments",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df",
            "id": "BatchRunComponent-ACGxu",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-YouTubeCommentsComponent-GFgM6{œdataTypeœ:œYouTubeCommentsComponentœ,œidœ:œYouTubeCommentsComponent-GFgM6œ,œnameœ:œcommentsœ,œoutput_typesœ:[œDataFrameœ]}-BatchRunComponent-ACGxu{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-ACGxuœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "YouTubeCommentsComponent-GFgM6",
        "sourceHandle": "{œdataTypeœ:œYouTubeCommentsComponentœ,œidœ:œYouTubeCommentsComponent-GFgM6œ,œnameœ:œcommentsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "BatchRunComponent-ACGxu",
        "targetHandle": "{œfieldNameœ:œdfœ,œidœ:œBatchRunComponent-ACGxuœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-5BznG",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "video_url",
            "id": "YouTubeCommentsComponent-GFgM6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-5BznG{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-YouTubeCommentsComponent-GFgM6{œfieldNameœ:œvideo_urlœ,œidœ:œYouTubeCommentsComponent-GFgM6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-5BznG",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "YouTubeCommentsComponent-GFgM6",
        "targetHandle": "{œfieldNameœ:œvideo_urlœ,œidœ:œYouTubeCommentsComponent-GFgM6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-5BznG",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "url",
            "id": "Prompt-XcN1h",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-5BznG{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-Prompt-XcN1h{œfieldNameœ:œurlœ,œidœ:œPrompt-XcN1hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-5BznG",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-XcN1h",
        "targetHandle": "{œfieldNameœ:œurlœ,œidœ:œPrompt-XcN1hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "BatchRunComponent",
            "id": "BatchRunComponent-ACGxu",
            "name": "batch_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "parser-1zzbG",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-BatchRunComponent-ACGxu{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-ACGxuœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}-parser-1zzbG{œfieldNameœ:œinput_dataœ,œidœ:œparser-1zzbGœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "BatchRunComponent-ACGxu",
        "sourceHandle": "{œdataTypeœ:œBatchRunComponentœ,œidœ:œBatchRunComponent-ACGxuœ,œnameœ:œbatch_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "parser-1zzbG",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œparser-1zzbGœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "parser",
            "id": "parser-1zzbG",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "analysis",
            "id": "Prompt-XcN1h",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-parser-1zzbG{œdataTypeœ:œparserœ,œidœ:œparser-1zzbGœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt-XcN1h{œfieldNameœ:œanalysisœ,œidœ:œPrompt-XcN1hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "parser-1zzbG",
        "sourceHandle": "{œdataTypeœ:œparserœ,œidœ:œparser-1zzbGœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-XcN1h",
        "targetHandle": "{œfieldNameœ:œanalysisœ,œidœ:œPrompt-XcN1hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GoogleGenerativeAIModel",
            "id": "GoogleGenerativeAIModel-DbMDo",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "model",
            "id": "BatchRunComponent-ACGxu",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-GoogleGenerativeAIModel-DbMDo{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-DbMDoœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-BatchRunComponent-ACGxu{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-ACGxuœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "GoogleGenerativeAIModel-DbMDo",
        "sourceHandle": "{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-DbMDoœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "BatchRunComponent-ACGxu",
        "targetHandle": "{œfieldNameœ:œmodelœ,œidœ:œBatchRunComponent-ACGxuœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-15NlD",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "api_key",
            "id": "GoogleGenerativeAIModel-DbMDo",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-15NlD{œdataTypeœ:œTextInputœ,œidœ:œTextInput-15NlDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-GoogleGenerativeAIModel-DbMDo{œfieldNameœ:œapi_keyœ,œidœ:œGoogleGenerativeAIModel-DbMDoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-15NlD",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-15NlDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GoogleGenerativeAIModel-DbMDo",
        "targetHandle": "{œfieldNameœ:œapi_keyœ,œidœ:œGoogleGenerativeAIModel-DbMDoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-dzcWx",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "api_key",
            "id": "YouTubeCommentsComponent-GFgM6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-dzcWx{œdataTypeœ:œTextInputœ,œidœ:œTextInput-dzcWxœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-YouTubeCommentsComponent-GFgM6{œfieldNameœ:œapi_keyœ,œidœ:œYouTubeCommentsComponent-GFgM6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-dzcWx",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-dzcWxœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "YouTubeCommentsComponent-GFgM6",
        "targetHandle": "{œfieldNameœ:œapi_keyœ,œidœ:œYouTubeCommentsComponent-GFgM6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-dzcWx",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "api_key",
            "id": "YouTubeVideoDetailsComponent-cZuZD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-dzcWx{œdataTypeœ:œTextInputœ,œidœ:œTextInput-dzcWxœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-YouTubeVideoDetailsComponent-cZuZD{œfieldNameœ:œapi_keyœ,œidœ:œYouTubeVideoDetailsComponent-cZuZDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-dzcWx",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-dzcWxœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "YouTubeVideoDetailsComponent-cZuZD",
        "targetHandle": "{œfieldNameœ:œapi_keyœ,œidœ:œYouTubeVideoDetailsComponent-cZuZDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-5BznG",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "video_url",
            "id": "YouTubeVideoDetailsComponent-cZuZD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-5BznG{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-YouTubeVideoDetailsComponent-cZuZD{œfieldNameœ:œvideo_urlœ,œidœ:œYouTubeVideoDetailsComponent-cZuZDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-5BznG",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "YouTubeVideoDetailsComponent-cZuZD",
        "targetHandle": "{œfieldNameœ:œvideo_urlœ,œidœ:œYouTubeVideoDetailsComponent-cZuZDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-XcN1h",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text1",
            "id": "CombineText-A3QhA",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-XcN1h{œdataTypeœ:œPromptœ,œidœ:œPrompt-XcN1hœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CombineText-A3QhA{œfieldNameœ:œtext1œ,œidœ:œCombineText-A3QhAœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-XcN1h",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-XcN1hœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-A3QhA",
        "targetHandle": "{œfieldNameœ:œtext1œ,œidœ:œCombineText-A3QhAœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-5BznG",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "url",
            "id": "Prompt-4mHFH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-5BznG{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-Prompt-4mHFH{œfieldNameœ:œurlœ,œidœ:œPrompt-4mHFHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-5BznG",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-4mHFH",
        "targetHandle": "{œfieldNameœ:œurlœ,œidœ:œPrompt-4mHFHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "parser",
            "id": "parser-2D3Sm",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "stats",
            "id": "Prompt-4mHFH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-parser-2D3Sm{œdataTypeœ:œparserœ,œidœ:œparser-2D3Smœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt-4mHFH{œfieldNameœ:œstatsœ,œidœ:œPrompt-4mHFHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "parser-2D3Sm",
        "sourceHandle": "{œdataTypeœ:œparserœ,œidœ:œparser-2D3Smœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-4mHFH",
        "targetHandle": "{œfieldNameœ:œstatsœ,œidœ:œPrompt-4mHFHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-4mHFH",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-A3QhA",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-4mHFH{œdataTypeœ:œPromptœ,œidœ:œPrompt-4mHFHœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CombineText-A3QhA{œfieldNameœ:œtext2œ,œidœ:œCombineText-A3QhAœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-4mHFH",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-4mHFHœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-A3QhA",
        "targetHandle": "{œfieldNameœ:œtext2œ,œidœ:œCombineText-A3QhAœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "YouTubeVideoDetailsComponent",
            "id": "YouTubeVideoDetailsComponent-cZuZD",
            "name": "video_data",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "parser-2D3Sm",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-YouTubeVideoDetailsComponent-cZuZD{œdataTypeœ:œYouTubeVideoDetailsComponentœ,œidœ:œYouTubeVideoDetailsComponent-cZuZDœ,œnameœ:œvideo_dataœ,œoutput_typesœ:[œDataFrameœ]}-parser-2D3Sm{œfieldNameœ:œinput_dataœ,œidœ:œparser-2D3Smœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "YouTubeVideoDetailsComponent-cZuZD",
        "sourceHandle": "{œdataTypeœ:œYouTubeVideoDetailsComponentœ,œidœ:œYouTubeVideoDetailsComponent-cZuZDœ,œnameœ:œvideo_dataœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "parser-2D3Sm",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œparser-2D3Smœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-5BznG",
            "name": "false_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-HJZVT",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-5BznG{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-HJZVT{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-HJZVTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-5BznG",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-HJZVT",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-HJZVTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-5BznG",
            "name": "false_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-HJZVT",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-5BznG{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-HJZVT{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-HJZVTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-5BznG",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-HJZVT",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-HJZVTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-rQT8F",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "GoogleGenerativeAIModel-uStvr",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-rQT8F{œdataTypeœ:œChatInputœ,œidœ:œChatInput-rQT8Fœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-GoogleGenerativeAIModel-uStvr{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-uStvrœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-rQT8F",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-rQT8Fœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GoogleGenerativeAIModel-uStvr",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-uStvrœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-15NlD",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "api_key",
            "id": "GoogleGenerativeAIModel-uStvr",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-15NlD{œdataTypeœ:œTextInputœ,œidœ:œTextInput-15NlDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-GoogleGenerativeAIModel-uStvr{œfieldNameœ:œapi_keyœ,œidœ:œGoogleGenerativeAIModel-uStvrœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-15NlD",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-15NlDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GoogleGenerativeAIModel-uStvr",
        "targetHandle": "{œfieldNameœ:œapi_keyœ,œidœ:œGoogleGenerativeAIModel-uStvrœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GoogleGenerativeAIModel",
            "id": "GoogleGenerativeAIModel-uStvr",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-5BznG",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-GoogleGenerativeAIModel-uStvr{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-uStvrœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-5BznG{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-5BznGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "GoogleGenerativeAIModel-uStvr",
        "sourceHandle": "{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-uStvrœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-5BznG",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-5BznGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GoogleGenerativeAIModel",
            "id": "GoogleGenerativeAIModel-uStvr",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-5BznG",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-GoogleGenerativeAIModel-uStvr{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-uStvrœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-5BznG{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-5BznGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "GoogleGenerativeAIModel-uStvr",
        "sourceHandle": "{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-uStvrœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-5BznG",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-5BznGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-HJZVT",
            "name": "false_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-ByYQm",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-HJZVT{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-HJZVTœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-ByYQm{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ByYQmœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-HJZVT",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-HJZVTœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-ByYQm",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ByYQmœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-HJZVT",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "channel_url",
            "id": "YouTubeChannelComponent-nVnTS",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-HJZVT{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-HJZVTœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-YouTubeChannelComponent-nVnTS{œfieldNameœ:œchannel_urlœ,œidœ:œYouTubeChannelComponent-nVnTSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-HJZVT",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-HJZVTœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "YouTubeChannelComponent-nVnTS",
        "targetHandle": "{œfieldNameœ:œchannel_urlœ,œidœ:œYouTubeChannelComponent-nVnTSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-dzcWx",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "api_key",
            "id": "YouTubeChannelComponent-nVnTS",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-dzcWx{œdataTypeœ:œTextInputœ,œidœ:œTextInput-dzcWxœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-YouTubeChannelComponent-nVnTS{œfieldNameœ:œapi_keyœ,œidœ:œYouTubeChannelComponent-nVnTSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-dzcWx",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-dzcWxœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "YouTubeChannelComponent-nVnTS",
        "targetHandle": "{œfieldNameœ:œapi_keyœ,œidœ:œYouTubeChannelComponent-nVnTSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "YouTubeChannelComponent",
            "id": "YouTubeChannelComponent-nVnTS",
            "name": "channel_df",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "parser-ABlBu",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-YouTubeChannelComponent-nVnTS{œdataTypeœ:œYouTubeChannelComponentœ,œidœ:œYouTubeChannelComponent-nVnTSœ,œnameœ:œchannel_dfœ,œoutput_typesœ:[œDataFrameœ]}-parser-ABlBu{œfieldNameœ:œinput_dataœ,œidœ:œparser-ABlBuœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "YouTubeChannelComponent-nVnTS",
        "sourceHandle": "{œdataTypeœ:œYouTubeChannelComponentœ,œidœ:œYouTubeChannelComponent-nVnTSœ,œnameœ:œchannel_dfœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "parser-ABlBu",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œparser-ABlBuœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "parser",
            "id": "parser-ABlBu",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "stats",
            "id": "Prompt-goJvm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-parser-ABlBu{œdataTypeœ:œparserœ,œidœ:œparser-ABlBuœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt-goJvm{œfieldNameœ:œstatsœ,œidœ:œPrompt-goJvmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "parser-ABlBu",
        "sourceHandle": "{œdataTypeœ:œparserœ,œidœ:œparser-ABlBuœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-goJvm",
        "targetHandle": "{œfieldNameœ:œstatsœ,œidœ:œPrompt-goJvmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-HJZVT",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "url",
            "id": "Prompt-goJvm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-HJZVT{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-HJZVTœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-Prompt-goJvm{œfieldNameœ:œurlœ,œidœ:œPrompt-goJvmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-HJZVT",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-HJZVTœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-goJvm",
        "targetHandle": "{œfieldNameœ:œurlœ,œidœ:œPrompt-goJvmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-15NlD",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "api_key",
            "id": "GoogleGenerativeAIModel-N7NVN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-15NlD{œdataTypeœ:œTextInputœ,œidœ:œTextInput-15NlDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-GoogleGenerativeAIModel-N7NVN{œfieldNameœ:œapi_keyœ,œidœ:œGoogleGenerativeAIModel-N7NVNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-15NlD",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-15NlDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GoogleGenerativeAIModel-N7NVN",
        "targetHandle": "{œfieldNameœ:œapi_keyœ,œidœ:œGoogleGenerativeAIModel-N7NVNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CombineText",
            "id": "CombineText-A3QhA",
            "name": "combined_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-zsxGB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-CombineText-A3QhA{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-A3QhAœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-zsxGB{œfieldNameœ:œtext2œ,œidœ:œCombineText-zsxGBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CombineText-A3QhA",
        "sourceHandle": "{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-A3QhAœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-zsxGB",
        "targetHandle": "{œfieldNameœ:œtext2œ,œidœ:œCombineText-zsxGBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CombineText",
            "id": "CombineText-zsxGB",
            "name": "combined_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "GoogleGenerativeAIModel-N7NVN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-CombineText-zsxGB{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-zsxGBœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}-GoogleGenerativeAIModel-N7NVN{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-N7NVNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CombineText-zsxGB",
        "sourceHandle": "{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-zsxGBœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GoogleGenerativeAIModel-N7NVN",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-N7NVNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-5BznG",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "url",
            "id": "YouTubeTranscripts-MQQNt",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-5BznG{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-YouTubeTranscripts-MQQNt{œfieldNameœ:œurlœ,œidœ:œYouTubeTranscripts-MQQNtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-5BznG",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "YouTubeTranscripts-MQQNt",
        "targetHandle": "{œfieldNameœ:œurlœ,œidœ:œYouTubeTranscripts-MQQNtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-5BznG",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "url",
            "id": "Prompt-umnnZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-5BznG{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-Prompt-umnnZ{œfieldNameœ:œurlœ,œidœ:œPrompt-umnnZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-5BznG",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5BznGœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-umnnZ",
        "targetHandle": "{œfieldNameœ:œurlœ,œidœ:œPrompt-umnnZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-umnnZ",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text1",
            "id": "CombineText-zsxGB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-umnnZ{œdataTypeœ:œPromptœ,œidœ:œPrompt-umnnZœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CombineText-zsxGB{œfieldNameœ:œtext1œ,œidœ:œCombineText-zsxGBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-umnnZ",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-umnnZœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-zsxGB",
        "targetHandle": "{œfieldNameœ:œtext1œ,œidœ:œCombineText-zsxGBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-goJvm",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "GoogleGenerativeAIModel-it4Oo",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-goJvm{œdataTypeœ:œPromptœ,œidœ:œPrompt-goJvmœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-GoogleGenerativeAIModel-it4Oo{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-it4Ooœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-goJvm",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-goJvmœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GoogleGenerativeAIModel-it4Oo",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œGoogleGenerativeAIModel-it4Ooœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-15NlD",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "api_key",
            "id": "GoogleGenerativeAIModel-it4Oo",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-15NlD{œdataTypeœ:œTextInputœ,œidœ:œTextInput-15NlDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-GoogleGenerativeAIModel-it4Oo{œfieldNameœ:œapi_keyœ,œidœ:œGoogleGenerativeAIModel-it4Ooœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-15NlD",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-15NlDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GoogleGenerativeAIModel-it4Oo",
        "targetHandle": "{œfieldNameœ:œapi_keyœ,œidœ:œGoogleGenerativeAIModel-it4Ooœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "YouTubeTranscripts",
            "id": "YouTubeTranscripts-MQQNt",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "transcript",
            "id": "Prompt-umnnZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-YouTubeTranscripts-MQQNt{œdataTypeœ:œYouTubeTranscriptsœ,œidœ:œYouTubeTranscripts-MQQNtœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-umnnZ{œfieldNameœ:œtranscriptœ,œidœ:œPrompt-umnnZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "YouTubeTranscripts-MQQNt",
        "sourceHandle": "{œdataTypeœ:œYouTubeTranscriptsœ,œidœ:œYouTubeTranscripts-MQQNtœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-umnnZ",
        "targetHandle": "{œfieldNameœ:œtranscriptœ,œidœ:œPrompt-umnnZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GoogleGenerativeAIModel",
            "id": "GoogleGenerativeAIModel-N7NVN",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-7WtZf",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-GoogleGenerativeAIModel-N7NVN{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-N7NVNœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CombineText-7WtZf{œfieldNameœ:œtext2œ,œidœ:œCombineText-7WtZfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "GoogleGenerativeAIModel-N7NVN",
        "sourceHandle": "{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-N7NVNœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-7WtZf",
        "targetHandle": "{œfieldNameœ:œtext2œ,œidœ:œCombineText-7WtZfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CombineText",
            "id": "CombineText-7WtZf",
            "name": "combined_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-hZf3B",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-CombineText-7WtZf{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-7WtZfœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-hZf3B{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-hZf3Bœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CombineText-7WtZf",
        "sourceHandle": "{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-7WtZfœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-hZf3B",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-hZf3Bœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "parser",
            "id": "parser-2D3Sm",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text1",
            "id": "CombineText-7WtZf",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-parser-2D3Sm{œdataTypeœ:œparserœ,œidœ:œparser-2D3Smœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-7WtZf{œfieldNameœ:œtext1œ,œidœ:œCombineText-7WtZfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "parser-2D3Sm",
        "sourceHandle": "{œdataTypeœ:œparserœ,œidœ:œparser-2D3Smœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-7WtZf",
        "targetHandle": "{œfieldNameœ:œtext1œ,œidœ:œCombineText-7WtZfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GoogleGenerativeAIModel",
            "id": "GoogleGenerativeAIModel-it4Oo",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-6WywH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-GoogleGenerativeAIModel-it4Oo{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-it4Ooœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CombineText-6WywH{œfieldNameœ:œtext2œ,œidœ:œCombineText-6WywHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "GoogleGenerativeAIModel-it4Oo",
        "sourceHandle": "{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-it4Ooœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-6WywH",
        "targetHandle": "{œfieldNameœ:œtext2œ,œidœ:œCombineText-6WywHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "parser",
            "id": "parser-ABlBu",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text1",
            "id": "CombineText-6WywH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-parser-ABlBu{œdataTypeœ:œparserœ,œidœ:œparser-ABlBuœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CombineText-6WywH{œfieldNameœ:œtext1œ,œidœ:œCombineText-6WywHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "parser-ABlBu",
        "sourceHandle": "{œdataTypeœ:œparserœ,œidœ:œparser-ABlBuœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-6WywH",
        "targetHandle": "{œfieldNameœ:œtext1œ,œidœ:œCombineText-6WywHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CombineText",
            "id": "CombineText-6WywH",
            "name": "combined_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-sFwPn",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CombineText-6WywH{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-6WywHœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-sFwPn{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-sFwPnœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CombineText-6WywH",
        "sourceHandle": "{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-6WywHœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-sFwPn",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-sFwPnœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "BatchRunComponent-ACGxu",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": true,
            "category": "helpers",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs a language model over each row of a DataFrame's text column and returns a new DataFrame with two columns: 'text_input' (the original text) and 'model_response' containing the model's response.",
            "display_name": "Batch Run",
            "documentation": "",
            "edited": false,
            "field_order": [
              "model",
              "system_message",
              "df",
              "column_name"
            ],
            "frozen": false,
            "icon": "List",
            "key": "BatchRunComponent",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Batch Results",
                "method": "run_batch",
                "name": "batch_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nimport operator\nfrom typing import TYPE_CHECKING, Any\n\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    DataFrameInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = (\n        \"Runs a language model over each row of a DataFrame's text column and returns a new \"\n        \"DataFrame with three columns: '**text_input**' (the original text),  \"\n        \"'**model_response**' (the model's response),and '**batch_index**' (the processing order).\"\n    )\n    icon = \"List\"\n    beta = True\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=\"The name of the DataFrame column to treat as text messages. Default='text'.\",\n            value=\"text\",\n            required=True,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Batch Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with columns: 'text_input', 'model_response', 'batch_index', and 'metadata'.\",\n        ),\n    ]\n\n    def _create_base_row(self, text_input: str = \"\", model_response: str = \"\", batch_index: int = -1) -> dict[str, Any]:\n        \"\"\"Create a base row with optional metadata.\"\"\"\n        return {\n            \"text_input\": text_input,\n            \"model_response\": model_response,\n            \"batch_index\": batch_index,\n        }\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row[\"text_input\"]),\n                \"response_length\": len(row[\"model_response\"]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - text_input: The original input text\n                - model_response: The model's response\n                - batch_index: The processing order\n                - metadata: Additional processing information\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"text\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Convert the specified column to a list of strings\n            user_texts = df[col_name].astype(str).tolist()\n            total_rows = len(user_texts)\n\n            logger.info(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n\n            # Process batches and track progress\n            responses_with_idx = [\n                (idx, response)\n                for idx, response in zip(\n                    range(len(conversations)), await model.abatch(list(conversations)), strict=True\n                )\n            ]\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=operator.itemgetter(0))\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, response in responses_with_idx:\n                resp_text = response.content if hasattr(response, \"content\") else str(response)\n                row = self._create_base_row(\n                    text_input=user_texts[idx],\n                    model_response=resp_text,\n                    batch_index=idx,\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    logger.info(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            logger.info(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            logger.error(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row()\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"
              },
              "column_name": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Column Name",
                "dynamic": false,
                "info": "The name of the DataFrame column to treat as text messages. Default='text'.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "column_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text"
              },
              "df": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "DataFrame",
                "dynamic": false,
                "info": "The DataFrame whose column (specified by 'column_name') we'll treat as text messages.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Enable Metadata",
                "dynamic": false,
                "info": "If True, add metadata to the output DataFrame.",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Connect the 'Language Model' output from your LLM component here.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "Multi-line system instruction for all rows in the DataFrame.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a sentiment analysis AI specialized in analyzing YouTube comments. Your task is to determine the emotional tone of each comment.\n\nAnalyze:\n- Word choice and tone\n- Emotional language \n- Context clues (emojis, punctuation, caps)\n\nClassify sentiment as:\n- Positive\n- Negative  \n- Neutral\n- Mixed\n- Sarcastic\n\nFormat:\n<sentiment_analysis>\n<concise_reasoning>\n[Brief 1-2 sentence analysis focusing on key emotional indicators in english]\n</concise_reasoning>\n<sentiment_type>\n[Sentiment category]\n</sentiment_type>\n</sentiment_analysis>\n\nExample:\nComment: \"Wow, this video is absolutely amazing! The creator did an incredible job explaining complex topics so clearly. 👏👏👏\"\n<sentiment_analysis>\n<concise_reasoning>\nUses enthusiastic words (\"amazing\", \"incredible\") with applause emojis, showing strong appreciation for the content's clarity.\n</concise_reasoning>\n<sentiment_type>\nPositive\n</sentiment_type>\n</sentiment_analysis>"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BatchRunComponent"
        },
        "dragging": false,
        "id": "BatchRunComponent-ACGxu",
        "measured": {
          "height": 401,
          "width": 320
        },
        "position": {
          "x": 2414.303173150446,
          "y": 435.6799212740059
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "YouTubeCommentsComponent-GFgM6",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "youtube",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieves and analyzes comments from YouTube videos.",
            "display_name": "YouTube Comments",
            "documentation": "",
            "edited": false,
            "field_order": [
              "video_url",
              "api_key",
              "max_results",
              "sort_by",
              "include_replies",
              "include_metrics"
            ],
            "frozen": false,
            "icon": "YouTube",
            "key": "YouTubeCommentsComponent",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Comments",
                "method": "get_video_comments",
                "name": "comments",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.1676812955549333,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "YouTube API Key",
                "dynamic": false,
                "info": "Your YouTube Data API key.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from contextlib import contextmanager\n\nimport pandas as pd\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nfrom langflow.custom import Component\nfrom langflow.inputs import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput\nfrom langflow.schema import DataFrame\nfrom langflow.template import Output\n\n\nclass YouTubeCommentsComponent(Component):\n    \"\"\"A component that retrieves comments from YouTube videos.\"\"\"\n\n    display_name: str = \"YouTube Comments\"\n    description: str = \"Retrieves and analyzes comments from YouTube videos.\"\n    icon: str = \"YouTube\"\n\n    # Constants\n    COMMENTS_DISABLED_STATUS = 403\n    NOT_FOUND_STATUS = 404\n    API_MAX_RESULTS = 100\n\n    inputs = [\n        MessageTextInput(\n            name=\"video_url\",\n            display_name=\"Video URL\",\n            info=\"The URL of the YouTube video to get comments from.\",\n            tool_mode=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"YouTube API Key\",\n            info=\"Your YouTube Data API key.\",\n            required=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            value=20,\n            info=\"The maximum number of comments to return.\",\n        ),\n        DropdownInput(\n            name=\"sort_by\",\n            display_name=\"Sort By\",\n            options=[\"time\", \"relevance\"],\n            value=\"relevance\",\n            info=\"Sort comments by time or relevance.\",\n        ),\n        BoolInput(\n            name=\"include_replies\",\n            display_name=\"Include Replies\",\n            value=False,\n            info=\"Whether to include replies to comments.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_metrics\",\n            display_name=\"Include Metrics\",\n            value=True,\n            info=\"Include metrics like like count and reply count.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"comments\", display_name=\"Comments\", method=\"get_video_comments\"),\n    ]\n\n    def _extract_video_id(self, video_url: str) -> str:\n        \"\"\"Extracts the video ID from a YouTube URL.\"\"\"\n        import re\n\n        patterns = [\n            r\"(?:youtube\\.com\\/watch\\?v=|youtu.be\\/|youtube.com\\/embed\\/)([^&\\n?#]+)\",\n            r\"youtube.com\\/shorts\\/([^&\\n?#]+)\",\n        ]\n\n        for pattern in patterns:\n            match = re.search(pattern, video_url)\n            if match:\n                return match.group(1)\n\n        return video_url.strip()\n\n    def _process_reply(self, reply: dict, parent_id: str, *, include_metrics: bool = True) -> dict:\n        \"\"\"Process a single reply comment.\"\"\"\n        reply_snippet = reply[\"snippet\"]\n        reply_data = {\n            \"comment_id\": reply[\"id\"],\n            \"parent_comment_id\": parent_id,\n            \"author\": reply_snippet[\"authorDisplayName\"],\n            \"text\": reply_snippet[\"textDisplay\"],\n            \"published_at\": reply_snippet[\"publishedAt\"],\n            \"is_reply\": True,\n        }\n        if include_metrics:\n            reply_data[\"like_count\"] = reply_snippet[\"likeCount\"]\n            reply_data[\"reply_count\"] = 0  # Replies can't have replies\n\n        return reply_data\n\n    def _process_comment(\n        self, item: dict, *, include_metrics: bool = True, include_replies: bool = False\n    ) -> list[dict]:\n        \"\"\"Process a single comment thread.\"\"\"\n        comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n        comment_id = item[\"snippet\"][\"topLevelComment\"][\"id\"]\n\n        # Basic comment data\n        processed_comments = [\n            {\n                \"comment_id\": comment_id,\n                \"parent_comment_id\": \"\",  # Empty for top-level comments\n                \"author\": comment[\"authorDisplayName\"],\n                \"author_channel_url\": comment.get(\"authorChannelUrl\", \"\"),\n                \"text\": comment[\"textDisplay\"],\n                \"published_at\": comment[\"publishedAt\"],\n                \"updated_at\": comment[\"updatedAt\"],\n                \"is_reply\": False,\n            }\n        ]\n\n        # Add metrics if requested\n        if include_metrics:\n            processed_comments[0].update(\n                {\n                    \"like_count\": comment[\"likeCount\"],\n                    \"reply_count\": item[\"snippet\"][\"totalReplyCount\"],\n                }\n            )\n\n        # Add replies if requested\n        if include_replies and item[\"snippet\"][\"totalReplyCount\"] > 0 and \"replies\" in item:\n            for reply in item[\"replies\"][\"comments\"]:\n                reply_data = self._process_reply(reply, parent_id=comment_id, include_metrics=include_metrics)\n                processed_comments.append(reply_data)\n\n        return processed_comments\n\n    @contextmanager\n    def youtube_client(self):\n        \"\"\"Context manager for YouTube API client.\"\"\"\n        client = build(\"youtube\", \"v3\", developerKey=self.api_key)\n        try:\n            yield client\n        finally:\n            client.close()\n\n    def get_video_comments(self) -> DataFrame:\n        \"\"\"Retrieves comments from a YouTube video and returns as DataFrame.\"\"\"\n        try:\n            # Extract video ID from URL\n            video_id = self._extract_video_id(self.video_url)\n\n            # Use context manager for YouTube API client\n            with self.youtube_client() as youtube:\n                comments_data = []\n                results_count = 0\n                request = youtube.commentThreads().list(\n                    part=\"snippet,replies\",\n                    videoId=video_id,\n                    maxResults=min(self.API_MAX_RESULTS, self.max_results),\n                    order=self.sort_by,\n                    textFormat=\"plainText\",\n                )\n\n                while request and results_count < self.max_results:\n                    response = request.execute()\n\n                    for item in response.get(\"items\", []):\n                        if results_count >= self.max_results:\n                            break\n\n                        comments = self._process_comment(\n                            item, include_metrics=self.include_metrics, include_replies=self.include_replies\n                        )\n                        comments_data.extend(comments)\n                        results_count += 1\n\n                    # Get the next page if available and needed\n                    if \"nextPageToken\" in response and results_count < self.max_results:\n                        request = youtube.commentThreads().list(\n                            part=\"snippet,replies\",\n                            videoId=video_id,\n                            maxResults=min(self.API_MAX_RESULTS, self.max_results - results_count),\n                            order=self.sort_by,\n                            textFormat=\"plainText\",\n                            pageToken=response[\"nextPageToken\"],\n                        )\n                    else:\n                        request = None\n\n                # Convert to DataFrame\n                comments_df = pd.DataFrame(comments_data)\n\n                # Add video metadata\n                comments_df[\"video_id\"] = video_id\n                comments_df[\"video_url\"] = self.video_url\n\n                # Sort columns for better organization\n                column_order = [\n                    \"video_id\",\n                    \"video_url\",\n                    \"comment_id\",\n                    \"parent_comment_id\",\n                    \"is_reply\",\n                    \"author\",\n                    \"author_channel_url\",\n                    \"text\",\n                    \"published_at\",\n                    \"updated_at\",\n                ]\n\n                if self.include_metrics:\n                    column_order.extend([\"like_count\", \"reply_count\"])\n\n                comments_df = comments_df[column_order]\n\n                return DataFrame(comments_df)\n\n        except HttpError as e:\n            error_message = f\"YouTube API error: {e!s}\"\n            if e.resp.status == self.COMMENTS_DISABLED_STATUS:\n                error_message = \"Comments are disabled for this video or API quota exceeded.\"\n            elif e.resp.status == self.NOT_FOUND_STATUS:\n                error_message = \"Video not found.\"\n\n            return DataFrame(pd.DataFrame({\"error\": [error_message]}))\n"
              },
              "include_metrics": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Include Metrics",
                "dynamic": false,
                "info": "Include metrics like like count and reply count.",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_metrics",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "include_replies": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Include Replies",
                "dynamic": false,
                "info": "Whether to include replies to comments.",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_replies",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_results": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Max Results",
                "dynamic": false,
                "info": "The maximum number of comments to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "sort_by": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sort By",
                "dynamic": false,
                "info": "Sort comments by time or relevance.",
                "name": "sort_by",
                "options": [
                  "time",
                  "relevance"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "relevance"
              },
              "video_url": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Video URL",
                "dynamic": false,
                "info": "The URL of the YouTube video to get comments from.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "video_url",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "YouTubeCommentsComponent"
        },
        "dragging": false,
        "id": "YouTubeCommentsComponent-GFgM6",
        "measured": {
          "height": 501,
          "width": 320
        },
        "position": {
          "x": 2022.3691510368908,
          "y": 845.3761464616389
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-XcN1h",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "url",
                "analysis"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "analysis": {
                "advanced": false,
                "display_name": "analysis",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "analysis",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "\nVideo URL:\n{url}\n\n Comment Analysis:\n{analysis}"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "url": {
                "advanced": false,
                "display_name": "url",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-XcN1h",
        "measured": {
          "height": 489,
          "width": 320
        },
        "position": {
          "x": 3088.722364378237,
          "y": 436.2597929646242
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-hZf3B",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "outputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-hZf3B",
        "measured": {
          "height": 231,
          "width": 320
        },
        "position": {
          "x": 5158.994993289364,
          "y": 776.040840845404
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "YouTubeTranscripts-MQQNt",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts spoken content from YouTube videos with multiple output options.",
            "display_name": "YouTube Transcripts",
            "documentation": "",
            "edited": true,
            "field_order": [
              "url",
              "chunk_size_seconds",
              "translation"
            ],
            "frozen": false,
            "icon": "YouTube",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks",
                "hidden": null,
                "method": "get_dataframe_output",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Transcript",
                "hidden": null,
                "method": "get_message_output",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Transcript + Source",
                "hidden": null,
                "method": "get_data_output",
                "name": "data_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_size_seconds": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Chunk Size (seconds)",
                "dynamic": false,
                "info": "The size of each transcript chunk in seconds.",
                "list": false,
                "list_add_label": "Add More",
                "name": "chunk_size_seconds",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 60
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\nimport re\nfrom youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled, CouldNotRetrieveTranscript\nfrom langchain_community.document_loaders import YoutubeLoader\nfrom langchain_community.document_loaders.youtube import TranscriptFormat\n\nfrom langflow.custom import Component\nfrom langflow.inputs import DropdownInput, IntInput, MultilineInput\nfrom langflow.schema import Data, DataFrame, Message\nfrom langflow.template import Output\n\n\nclass YouTubeTranscriptsComponent(Component):\n    \"\"\"A component that extracts spoken content from YouTube videos as transcripts.\"\"\"\n\n    display_name: str = \"YouTube Transcripts\"\n    description: str = \"Extracts spoken content from YouTube videos with multiple output options.\"\n    icon: str = \"YouTube\"\n    name = \"YouTubeTranscripts\"\n\n    inputs = [\n        MultilineInput(\n            name=\"url\",\n            display_name=\"Video URL\",\n            info=\"Enter the YouTube video URL to get transcripts from.\",\n            tool_mode=True,\n            required=True,\n        ),\n        IntInput(\n            name=\"chunk_size_seconds\",\n            display_name=\"Chunk Size (seconds)\",\n            value=60,\n            info=\"The size of each transcript chunk in seconds.\",\n        ),\n        DropdownInput(\n            name=\"translation\",\n            display_name=\"Translation Language\",\n            advanced=True,\n            options=[\"\", \"en\", \"es\", \"fr\", \"de\", \"it\", \"pt\", \"ru\", \"ja\", \"ko\", \"hi\", \"ar\", \"id\"],\n            info=\"Translate the transcripts to the specified language. Leave empty for no translation.\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"dataframe\", display_name=\"Chunks\", method=\"get_dataframe_output\"),\n        Output(name=\"message\", display_name=\"Transcript\", method=\"get_message_output\"),\n        Output(name=\"data_output\", display_name=\"Transcript + Source\", method=\"get_data_output\"),\n    ]\n\n    def _extract_video_id(self, url: str) -> str:\n        match = re.search(r\"(?:v=|youtu\\.be/)([\\w-]+)\", url)\n        if not match:\n            raise ValueError(\"Invalid YouTube URL format.\")\n        return match.group(1)\n\n    def _fallback_transcript(self, video_id):\n        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n\n        # Try manually created transcripts first\n        try:\n            transcript = transcript_list.find_manually_created_transcript(['en', 'fr', 'es', 'de', 'it', 'pt'])\n        except NoTranscriptFound:\n            # Fallback to any available generated transcript\n            available = list(transcript_list._generated_transcripts.values())\n            if not available:\n                raise ValueError(\"No available transcripts in any language.\")\n            transcript = available[0]\n\n        return transcript.fetch()\n\n    def _load_transcripts(self, *, as_chunks: bool = True):\n        try:\n            loader = YoutubeLoader.from_youtube_url(\n                self.url,\n                transcript_format=TranscriptFormat.CHUNKS if as_chunks else TranscriptFormat.TEXT,\n                chunk_size_seconds=self.chunk_size_seconds,\n                translation=self.translation or None,\n            )\n            return loader.load()\n\n        except (NoTranscriptFound, TranscriptsDisabled, CouldNotRetrieveTranscript):\n            # Fallback manually if needed\n            video_id = self._extract_video_id(self.url)\n            transcript_data = self._fallback_transcript(video_id)\n\n            # Simulate the expected format\n            return [\n                type(\"TranscriptDoc\", (), {\n                    \"page_content\": \" \".join([t[\"text\"] for t in transcript_data]),\n                    \"metadata\": {\"start_seconds\": 0},\n                })()\n            ]\n\n    def get_dataframe_output(self) -> DataFrame:\n        try:\n            transcripts = self._load_transcripts(as_chunks=True)\n            data = []\n            for doc in transcripts:\n                start_seconds = int(doc.metadata.get(\"start_seconds\", 0))\n                start_minutes = start_seconds // 60\n                start_seconds %= 60\n                timestamp = f\"{start_minutes:02d}:{start_seconds:02d}\"\n                data.append({\"timestamp\": timestamp, \"text\": doc.page_content})\n\n            return DataFrame(pd.DataFrame(data))\n\n        except Exception as exc:\n            return DataFrame(pd.DataFrame({\"error\": [f\"Failed to get YouTube transcripts: {exc!s}\"]}))\n\n    def get_message_output(self) -> Message:\n        try:\n            transcripts = self._load_transcripts(as_chunks=False)\n            result = transcripts[0].page_content\n            return Message(text=result)\n\n        except Exception as exc:\n            return Message(text=f\"⚠️ Could not retrieve transcript:\\n{str(exc)}\")\n\n    def get_data_output(self) -> Data:\n        default_data = {\"transcript\": \"\", \"video_url\": self.url, \"error\": None}\n\n        try:\n            transcripts = self._load_transcripts(as_chunks=False)\n            if not transcripts:\n                default_data[\"error\"] = \"No transcripts found.\"\n                return Data(data=default_data)\n\n            full_transcript = \" \".join(doc.page_content for doc in transcripts)\n            return Data(data={\"transcript\": full_transcript, \"video_url\": self.url})\n\n        except Exception as exc:\n            default_data[\"error\"] = str(exc)\n            return Data(data=default_data)\n"
              },
              "translation": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Translation Language",
                "dynamic": false,
                "info": "Translate the transcripts to the specified language. Leave empty for no translation.",
                "name": "translation",
                "options": [
                  "",
                  "en",
                  "es",
                  "fr",
                  "de",
                  "it",
                  "pt",
                  "ru",
                  "ja",
                  "ko",
                  "hi",
                  "ar",
                  "id"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "url": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Video URL",
                "dynamic": false,
                "info": "Enter the YouTube video URL to get transcripts from.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "url",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "YouTubeTranscripts"
        },
        "dragging": false,
        "id": "YouTubeTranscripts-MQQNt",
        "measured": {
          "height": 431,
          "width": 320
        },
        "position": {
          "x": 3418.359541547672,
          "y": 435.97119687604265
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-rQT8F",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "inputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "URL video",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatInput",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0020353564437605998,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-rQT8F",
        "measured": {
          "height": 273,
          "width": 320
        },
        "position": {
          "x": 468.972800189188,
          "y": 1122.9923732899729
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-5BznG",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "key": "ConditionalRouter",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "method": "true_response",
                "name": "true_result",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "method": "false_response",
                "name": "false_result",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "^(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/watch\\?v=|youtu\\.be\\/)([A-Za-z0-9_-]{11})(?:&\\S*)?$"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "The message to pass through either route.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "regex"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-5BznG",
        "measured": {
          "height": 591,
          "width": 320
        },
        "position": {
          "x": 1212.906728633231,
          "y": 1120.9470834086135
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "parser-1zzbG",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Format a DataFrame or Data object into text using a template. Enable 'Stringify' to convert input into a readable string instead.",
            "display_name": "Parser",
            "documentation": "",
            "edited": false,
            "field_order": [
              "mode",
              "pattern",
              "input_data",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "parser",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 2.220446049250313e-16,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TabInput,\n)\nfrom langflow.schema import Data, DataFrame\nfrom langflow.schema.message import Message\n\n\nclass ParserComponent(Component):\n    name = \"parser\"\n    display_name = \"Parser\"\n    description = (\n        \"Format a DataFrame or Data object into text using a template. \"\n        \"Enable 'Stringify' to convert input into a readable string instead.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                return json.dumps(data.data)\n            if isinstance(data, DataFrame):\n                if hasattr(self, \"clean_data\") and self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([self._safe_convert(item) for item in self.input_data])\n        else:\n            result = self._safe_convert(self.input_data)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "parser"
        },
        "dragging": false,
        "id": "parser-1zzbG",
        "measured": {
          "height": 398,
          "width": 320
        },
        "position": {
          "x": 2752.5585259656873,
          "y": 433.64549795161366
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GoogleGenerativeAIModel-DbMDo",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Google Generative AI.",
            "display_name": "Google Generative AI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_output_tokens",
              "model_name",
              "api_key",
              "top_p",
              "temperature",
              "n",
              "top_k",
              "tool_model_enabled"
            ],
            "frozen": false,
            "icon": "GoogleGenerativeAI",
            "key": "GoogleGenerativeAIModel",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00963430161181485,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Google API Key",
                "dynamic": false,
                "info": "The Google API Key to use for the Google Generative AI.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nimport requests\nfrom loguru import logger\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput, SliderInput\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.schema import dotdict\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_output_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=GOOGLE_GENERATIVE_AI_MODELS,\n            value=\"gemini-1.5-pro\",\n            refresh_button=True,\n            combobox=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n            required=True,\n            real_time_refresh=True,\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Tool Model Enabled\",\n            info=\"Whether to use the tool model.\",\n            value=False,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError as e:\n            msg = \"The 'langchain_google_genai' package is required to use the Google Generative AI model.\"\n            raise ImportError(msg) from e\n\n        google_api_key = self.api_key\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        return ChatGoogleGenerativeAI(\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key).get_secret_value(),\n        )\n\n    def get_models(self, tool_model_enabled: bool | None = None) -> list[str]:\n        try:\n            import google.generativeai as genai\n\n            genai.configure(api_key=self.api_key)\n            model_ids = [\n                model.name.replace(\"models/\", \"\")\n                for model in genai.list_models()\n                if \"generateContent\" in model.supported_generation_methods\n            ]\n            model_ids.sort(reverse=True)\n        except (ImportError, ValueError) as e:\n            logger.exception(f\"Error getting model names: {e}\")\n            model_ids = GOOGLE_GENERATIVE_AI_MODELS\n        if tool_model_enabled:\n            try:\n                from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n            except ImportError as e:\n                msg = \"langchain_google_genai is not installed.\"\n                raise ImportError(msg) from e\n            for model in model_ids:\n                model_with_tool = ChatGoogleGenerativeAI(\n                    model=self.model_name,\n                    google_api_key=self.api_key,\n                )\n                if not self.supports_tool_calling(model_with_tool):\n                    model_ids.remove(model)\n        return model_ids\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name in {\"base_url\", \"model_name\", \"tool_model_enabled\", \"api_key\"} and field_value:\n            try:\n                if len(self.api_key) == 0:\n                    ids = GOOGLE_GENERATIVE_AI_MODELS\n                else:\n                    try:\n                        ids = self.get_models(tool_model_enabled=self.tool_model_enabled)\n                    except (ImportError, ValueError, requests.exceptions.RequestException) as e:\n                        logger.exception(f\"Error getting model names: {e}\")\n                        ids = GOOGLE_GENERATIVE_AI_MODELS\n                build_config[\"model_name\"][\"options\"] = ids\n                build_config[\"model_name\"][\"value\"] = ids[0]\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_output_tokens": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Max Output Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_output_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "info": "The name of the model to use.",
                "name": "model_name",
                "options": [
                  "learnlm-1.5-pro-experimental",
                  "gemma-3-4b-it",
                  "gemma-3-27b-it",
                  "gemma-3-1b-it",
                  "gemma-3-12b-it",
                  "gemini-pro-vision",
                  "gemini-exp-1206",
                  "gemini-2.5-pro-preview-03-25",
                  "gemini-2.5-pro-exp-03-25",
                  "gemini-2.0-pro-exp-02-05",
                  "gemini-2.0-pro-exp",
                  "gemini-2.0-flash-thinking-exp-1219",
                  "gemini-2.0-flash-thinking-exp-01-21",
                  "gemini-2.0-flash-thinking-exp",
                  "gemini-2.0-flash-lite-preview-02-05",
                  "gemini-2.0-flash-lite-preview",
                  "gemini-2.0-flash-lite-001",
                  "gemini-2.0-flash-lite",
                  "gemini-2.0-flash-exp-image-generation",
                  "gemini-2.0-flash-exp",
                  "gemini-2.0-flash-001",
                  "gemini-2.0-flash",
                  "gemini-1.5-pro-latest",
                  "gemini-1.5-pro-002",
                  "gemini-1.5-pro-001",
                  "gemini-1.5-pro",
                  "gemini-1.5-flash-latest",
                  "gemini-1.5-flash-8b-latest",
                  "gemini-1.5-flash-8b-exp-0924",
                  "gemini-1.5-flash-8b-exp-0827",
                  "gemini-1.5-flash-8b-001",
                  "gemini-1.5-flash-8b",
                  "gemini-1.5-flash-002",
                  "gemini-1.5-flash-001-tuning",
                  "gemini-1.5-flash-001",
                  "gemini-1.5-flash",
                  "gemini-1.0-pro-vision-latest"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "learnlm-1.5-pro-experimental"
              },
              "n": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "N",
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Tool Model Enabled",
                "dynamic": false,
                "info": "Whether to use the tool model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "top_p": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Top P",
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_p",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "GoogleGenerativeAIModel"
        },
        "dragging": false,
        "id": "GoogleGenerativeAIModel-DbMDo",
        "measured": {
          "height": 744,
          "width": 320
        },
        "position": {
          "x": 2020.9305651739714,
          "y": 98.06148525239882
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-15NlD",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "",
            "display_name": "Gemini API Key",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-15NlD",
        "measured": {
          "height": 199,
          "width": 320
        },
        "position": {
          "x": 632.5435351947203,
          "y": 261.59719218328297
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-dzcWx",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "",
            "display_name": "YouTube API Key",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-dzcWx",
        "measured": {
          "height": 199,
          "width": 320
        },
        "position": {
          "x": 631.8529228120501,
          "y": 462.5789869678103
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "YouTubeVideoDetailsComponent-cZuZD",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "youtube",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieves detailed information and statistics about YouTube videos.",
            "display_name": "YouTube Video Details",
            "documentation": "",
            "edited": false,
            "field_order": [
              "video_url",
              "api_key",
              "include_statistics",
              "include_content_details",
              "include_tags",
              "include_thumbnails"
            ],
            "frozen": false,
            "icon": "YouTube",
            "key": "YouTubeVideoDetailsComponent",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Video Data",
                "hidden": null,
                "method": "get_video_details",
                "name": "video_data",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000018578044550916993,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "YouTube API Key",
                "dynamic": false,
                "info": "Your YouTube Data API key.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from contextlib import contextmanager\n\nimport googleapiclient\nimport pandas as pd\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nfrom langflow.custom import Component\nfrom langflow.inputs import BoolInput, MessageTextInput, SecretStrInput\nfrom langflow.schema import DataFrame\nfrom langflow.template import Output\n\n\nclass YouTubeVideoDetailsComponent(Component):\n    \"\"\"A component that retrieves detailed information about YouTube videos.\"\"\"\n\n    display_name: str = \"YouTube Video Details\"\n    description: str = \"Retrieves detailed information and statistics about YouTube videos.\"\n    icon: str = \"YouTube\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"video_url\",\n            display_name=\"Video URL\",\n            info=\"The URL of the YouTube video.\",\n            tool_mode=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"YouTube API Key\",\n            info=\"Your YouTube Data API key.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"include_statistics\",\n            display_name=\"Include Statistics\",\n            value=True,\n            info=\"Include video statistics (views, likes, comments).\",\n        ),\n        BoolInput(\n            name=\"include_content_details\",\n            display_name=\"Include Content Details\",\n            value=True,\n            info=\"Include video duration, quality, and age restriction info.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_tags\",\n            display_name=\"Include Tags\",\n            value=True,\n            info=\"Include video tags and keywords.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_thumbnails\",\n            display_name=\"Include Thumbnails\",\n            value=True,\n            info=\"Include video thumbnail URLs in different resolutions.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"video_data\", display_name=\"Video Data\", method=\"get_video_details\"),\n    ]\n\n    API_FORBIDDEN = 403\n    VIDEO_NOT_FOUND = 404\n\n    @contextmanager\n    def youtube_client(self):\n        \"\"\"Context manager for YouTube API client.\"\"\"\n        client = build(\"youtube\", \"v3\", developerKey=self.api_key)\n        try:\n            yield client\n        finally:\n            client.close()\n\n    def _extract_video_id(self, video_url: str) -> str:\n        \"\"\"Extracts the video ID from a YouTube URL.\"\"\"\n        import re\n\n        patterns = [\n            r\"(?:youtube\\.com\\/watch\\?v=|youtu.be\\/|youtube.com\\/embed\\/)([^&\\n?#]+)\",\n            r\"youtube.com\\/shorts\\/([^&\\n?#]+)\",\n        ]\n\n        for pattern in patterns:\n            match = re.search(pattern, video_url)\n            if match:\n                return match.group(1)\n\n        return video_url.strip()\n\n    def _format_duration(self, duration: str) -> str:\n        \"\"\"Formats the ISO 8601 duration to a readable format.\"\"\"\n        import re\n\n        hours = 0\n        minutes = 0\n        seconds = 0\n\n        hours_match = re.search(r\"(\\d+)H\", duration)\n        minutes_match = re.search(r\"(\\d+)M\", duration)\n        seconds_match = re.search(r\"(\\d+)S\", duration)\n\n        if hours_match:\n            hours = int(hours_match.group(1))\n        if minutes_match:\n            minutes = int(minutes_match.group(1))\n        if seconds_match:\n            seconds = int(seconds_match.group(1))\n\n        if hours > 0:\n            return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n        return f\"{minutes:02d}:{seconds:02d}\"\n\n    def get_video_details(self) -> DataFrame:\n        \"\"\"Retrieves detailed information about a YouTube video and returns as DataFrame.\"\"\"\n        try:\n            with self.youtube_client() as youtube:\n                # Extract video ID\n                video_id = self._extract_video_id(self.video_url)\n\n                # Prepare parts for the API request\n                parts = [\"snippet\"]\n                if self.include_statistics:\n                    parts.append(\"statistics\")\n                if self.include_content_details:\n                    parts.append(\"contentDetails\")\n\n                # Get video information\n                video_response = youtube.videos().list(part=\",\".join(parts), id=video_id).execute()\n\n                if not video_response[\"items\"]:\n                    return DataFrame(pd.DataFrame({\"error\": [\"Video not found\"]}))\n\n                video_info = video_response[\"items\"][0]\n                snippet = video_info[\"snippet\"]\n\n                # Build video data dictionary\n                video_data = {\n                    \"video_id\": [video_id],\n                    \"url\": [f\"https://www.youtube.com/watch?v={video_id}\"],\n                    \"title\": [snippet[\"title\"]],\n                    \"description\": [snippet[\"description\"]],\n                    \"published_at\": [snippet[\"publishedAt\"]],\n                    \"channel_id\": [snippet[\"channelId\"]],\n                    \"channel_title\": [snippet[\"channelTitle\"]],\n                    \"category_id\": [snippet.get(\"categoryId\", \"Unknown\")],\n                    \"live_broadcast_content\": [snippet.get(\"liveBroadcastContent\", \"none\")],\n                }\n\n                # Add thumbnails if requested\n                if self.include_thumbnails:\n                    for size, thumb in snippet[\"thumbnails\"].items():\n                        video_data[f\"thumbnail_{size}_url\"] = [thumb[\"url\"]]\n                        video_data[f\"thumbnail_{size}_width\"] = [thumb.get(\"width\", 0)]\n                        video_data[f\"thumbnail_{size}_height\"] = [thumb.get(\"height\", 0)]\n\n                # Add tags if requested\n                if self.include_tags and \"tags\" in snippet:\n                    video_data[\"tags\"] = [\", \".join(snippet[\"tags\"])]\n                    video_data[\"tags_count\"] = [len(snippet[\"tags\"])]\n\n                # Add statistics if requested\n                if self.include_statistics and \"statistics\" in video_info:\n                    stats = video_info[\"statistics\"]\n                    video_data.update(\n                        {\n                            \"view_count\": [int(stats.get(\"viewCount\", 0))],\n                            \"like_count\": [int(stats.get(\"likeCount\", 0))],\n                            \"favorite_count\": [int(stats.get(\"favoriteCount\", 0))],\n                            \"comment_count\": [int(stats.get(\"commentCount\", 0))],\n                        }\n                    )\n\n                # Add content details if requested\n                if self.include_content_details and \"contentDetails\" in video_info:\n                    content_details = video_info[\"contentDetails\"]\n                    video_data.update(\n                        {\n                            \"duration\": [self._format_duration(content_details[\"duration\"])],\n                            \"dimension\": [content_details.get(\"dimension\", \"2d\")],\n                            \"definition\": [content_details.get(\"definition\", \"hd\").upper()],\n                            \"has_captions\": [content_details.get(\"caption\", \"false\") == \"true\"],\n                            \"licensed_content\": [content_details.get(\"licensedContent\", False)],\n                            \"projection\": [content_details.get(\"projection\", \"rectangular\")],\n                            \"has_custom_thumbnails\": [content_details.get(\"hasCustomThumbnail\", False)],\n                        }\n                    )\n\n                    # Add content rating if available\n                    if \"contentRating\" in content_details:\n                        rating_info = content_details[\"contentRating\"]\n                        video_data[\"content_rating\"] = [str(rating_info)]\n\n                # Create DataFrame with organized columns\n                video_df = pd.DataFrame(video_data)\n\n                # Organize columns in logical groups\n                basic_cols = [\n                    \"video_id\",\n                    \"title\",\n                    \"url\",\n                    \"channel_id\",\n                    \"channel_title\",\n                    \"published_at\",\n                    \"category_id\",\n                    \"live_broadcast_content\",\n                    \"description\",\n                ]\n\n                stat_cols = [\"view_count\", \"like_count\", \"favorite_count\", \"comment_count\"]\n\n                content_cols = [\n                    \"duration\",\n                    \"dimension\",\n                    \"definition\",\n                    \"has_captions\",\n                    \"licensed_content\",\n                    \"projection\",\n                    \"has_custom_thumbnails\",\n                    \"content_rating\",\n                ]\n\n                tag_cols = [\"tags\", \"tags_count\"]\n\n                thumb_cols = [col for col in video_df.columns if col.startswith(\"thumbnail_\")]\n\n                # Reorder columns based on what's included\n                ordered_cols = basic_cols.copy()\n\n                if self.include_statistics:\n                    ordered_cols.extend([col for col in stat_cols if col in video_df.columns])\n\n                if self.include_content_details:\n                    ordered_cols.extend([col for col in content_cols if col in video_df.columns])\n\n                if self.include_tags:\n                    ordered_cols.extend([col for col in tag_cols if col in video_df.columns])\n\n                if self.include_thumbnails:\n                    ordered_cols.extend(sorted(thumb_cols))\n\n                # Add any remaining columns\n                remaining_cols = [col for col in video_df.columns if col not in ordered_cols]\n                ordered_cols.extend(remaining_cols)\n\n                return DataFrame(video_df[ordered_cols])\n\n        except (HttpError, googleapiclient.errors.HttpError) as e:\n            error_message = f\"YouTube API error: {e!s}\"\n            if e.resp.status == self.API_FORBIDDEN:\n                error_message = \"API quota exceeded or access forbidden.\"\n            elif e.resp.status == self.VIDEO_NOT_FOUND:\n                error_message = \"Video not found.\"\n\n            return DataFrame(pd.DataFrame({\"error\": [error_message]}))\n\n        except KeyError as e:\n            return DataFrame(pd.DataFrame({\"error\": [str(e)]}))\n"
              },
              "include_content_details": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Include Content Details",
                "dynamic": false,
                "info": "Include video duration, quality, and age restriction info.",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_content_details",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "include_statistics": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Include Statistics",
                "dynamic": false,
                "info": "Include video statistics (views, likes, comments).",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_statistics",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "include_tags": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Include Tags",
                "dynamic": false,
                "info": "Include video tags and keywords.",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_tags",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "include_thumbnails": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Include Thumbnails",
                "dynamic": false,
                "info": "Include video thumbnail URLs in different resolutions.",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_thumbnails",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "video_url": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Video URL",
                "dynamic": false,
                "info": "The URL of the YouTube video.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "video_url",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "YouTubeVideoDetailsComponent"
        },
        "dragging": false,
        "id": "YouTubeVideoDetailsComponent-cZuZD",
        "measured": {
          "height": 501,
          "width": 320
        },
        "position": {
          "x": 2759.2343050323966,
          "y": 1060.908904103712
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "parser-2D3Sm",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Format a DataFrame or Data object into text using a template. Enable 'Stringify' to convert input into a readable string instead.",
            "display_name": "Parser",
            "documentation": "",
            "edited": false,
            "field_order": [
              "mode",
              "pattern",
              "input_data",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "parser",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 2.220446049250313e-16,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Clean Data",
                "dynamic": false,
                "info": "Enable to clean the data by removing empty rows and lines in each cell of the DataFrame/ Data object.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TabInput,\n)\nfrom langflow.schema import Data, DataFrame\nfrom langflow.schema.message import Message\n\n\nclass ParserComponent(Component):\n    name = \"parser\"\n    display_name = \"Parser\"\n    description = (\n        \"Format a DataFrame or Data object into text using a template. \"\n        \"Enable 'Stringify' to convert input into a readable string instead.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                return json.dumps(data.data)\n            if isinstance(data, DataFrame):\n                if hasattr(self, \"clean_data\") and self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([self._safe_convert(item) for item in self.input_data])\n        else:\n            result = self._safe_convert(self.input_data)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Stringify"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "parser"
        },
        "dragging": false,
        "id": "parser-2D3Sm",
        "measured": {
          "height": 314,
          "width": 320
        },
        "position": {
          "x": 3089.5378882521163,
          "y": 1064.4283952431701
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CombineText-A3QhA",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "display_name": "Combine Text",
            "documentation": "",
            "edited": false,
            "field_order": [
              "text1",
              "text2",
              "delimiter"
            ],
            "frozen": false,
            "icon": "merge",
            "key": "CombineText",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined Text",
                "method": "combine_texts",
                "name": "combined_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n"
              },
              "delimiter": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Delimiter",
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "delimiter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " "
              },
              "text1": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "First Text",
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text1",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text2": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Second Text",
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text2",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CombineText"
        },
        "dragging": false,
        "id": "CombineText-A3QhA",
        "measured": {
          "height": 416,
          "width": 320
        },
        "position": {
          "x": 3749.8869589493042,
          "y": 1065.1311409909015
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-4mHFH",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "url",
                "stats"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "stats": {
                "advanced": false,
                "display_name": "stats",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "stats",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "\nVideo URL:\n{url}\n\nStatistics Analysis:\n{stats}"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "url": {
                "advanced": false,
                "display_name": "url",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-4mHFH",
        "measured": {
          "height": 489,
          "width": 320
        },
        "position": {
          "x": 3418.931342401984,
          "y": 1064.2567145922437
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-HJZVT",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "key": "ConditionalRouter",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "method": "true_response",
                "name": "true_result",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "method": "false_response",
                "name": "false_result",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "^(?:https?:\\/\\/)?(?:www\\.)?youtube\\.com\\/(?:channel\\/UC[\\w-]{21}[AQgw]|user\\/[\\w-]+|@[\\w-]+)\\/?$"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "The message to pass through either route.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "regex"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-HJZVT",
        "measured": {
          "height": 591,
          "width": 320
        },
        "position": {
          "x": 1969.6869712101625,
          "y": 1935.9713704424255
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "YouTubeChannelComponent-nVnTS",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "youtube",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieves detailed information and statistics about YouTube channels as a DataFrame.",
            "display_name": "YouTube Channel",
            "documentation": "",
            "edited": false,
            "field_order": [
              "channel_url",
              "api_key",
              "include_statistics",
              "include_branding",
              "include_playlists"
            ],
            "frozen": false,
            "icon": "YouTube",
            "key": "YouTubeChannelComponent",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Channel Info",
                "method": "get_channel_info",
                "name": "channel_df",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000007568328950209746,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "YouTube API Key",
                "dynamic": false,
                "info": "Your YouTube Data API key.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "channel_url": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Channel URL or ID",
                "dynamic": false,
                "info": "The URL or ID of the YouTube channel.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "channel_url",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\nfrom urllib.error import HTTPError\n\nimport pandas as pd\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nfrom langflow.custom import Component\nfrom langflow.inputs import BoolInput, MessageTextInput, SecretStrInput\nfrom langflow.schema import DataFrame\nfrom langflow.template import Output\n\n\nclass YouTubeChannelComponent(Component):\n    \"\"\"A component that retrieves detailed information about YouTube channels.\"\"\"\n\n    display_name: str = \"YouTube Channel\"\n    description: str = \"Retrieves detailed information and statistics about YouTube channels as a DataFrame.\"\n    icon: str = \"YouTube\"\n\n    # Constants\n    CHANNEL_ID_LENGTH = 24\n    QUOTA_EXCEEDED_STATUS = 403\n    NOT_FOUND_STATUS = 404\n    MAX_PLAYLIST_RESULTS = 10\n\n    inputs = [\n        MessageTextInput(\n            name=\"channel_url\",\n            display_name=\"Channel URL or ID\",\n            info=\"The URL or ID of the YouTube channel.\",\n            tool_mode=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"YouTube API Key\",\n            info=\"Your YouTube Data API key.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"include_statistics\",\n            display_name=\"Include Statistics\",\n            value=True,\n            info=\"Include channel statistics (views, subscribers, videos).\",\n        ),\n        BoolInput(\n            name=\"include_branding\",\n            display_name=\"Include Branding\",\n            value=True,\n            info=\"Include channel branding settings (banner, thumbnails).\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_playlists\",\n            display_name=\"Include Playlists\",\n            value=False,\n            info=\"Include channel's public playlists.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"channel_df\", display_name=\"Channel Info\", method=\"get_channel_info\"),\n    ]\n\n    def _extract_channel_id(self, channel_url: str) -> str:\n        \"\"\"Extracts the channel ID from various YouTube channel URL formats.\"\"\"\n        import re\n\n        if channel_url.startswith(\"UC\") and len(channel_url) == self.CHANNEL_ID_LENGTH:\n            return channel_url\n\n        patterns = {\n            \"custom_url\": r\"youtube\\.com\\/c\\/([^\\/\\n?]+)\",\n            \"channel_id\": r\"youtube\\.com\\/channel\\/([^\\/\\n?]+)\",\n            \"user\": r\"youtube\\.com\\/user\\/([^\\/\\n?]+)\",\n            \"handle\": r\"youtube\\.com\\/@([^\\/\\n?]+)\",\n        }\n\n        for pattern_type, pattern in patterns.items():\n            match = re.search(pattern, channel_url)\n            if match:\n                if pattern_type == \"channel_id\":\n                    return match.group(1)\n                return self._get_channel_id_by_name(match.group(1), pattern_type)\n\n        return channel_url\n\n    def _get_channel_id_by_name(self, channel_name: str, identifier_type: str) -> str:\n        \"\"\"Gets the channel ID using the channel name or custom URL.\"\"\"\n        youtube = None\n        try:\n            youtube = build(\"youtube\", \"v3\", developerKey=self.api_key)\n\n            if identifier_type == \"handle\":\n                channel_name = channel_name.lstrip(\"@\")\n\n            request = youtube.search().list(part=\"id\", q=channel_name, type=\"channel\", maxResults=1)\n            response = request.execute()\n\n            if response[\"items\"]:\n                return response[\"items\"][0][\"id\"][\"channelId\"]\n\n            error_msg = f\"Could not find channel ID for: {channel_name}\"\n            raise ValueError(error_msg)\n\n        except (HttpError, HTTPError) as e:\n            error_msg = f\"YouTube API error while getting channel ID: {e!s}\"\n            raise RuntimeError(error_msg) from e\n        except Exception as e:\n            error_msg = f\"Unexpected error while getting channel ID: {e!s}\"\n            raise ValueError(error_msg) from e\n        finally:\n            if youtube:\n                youtube.close()\n\n    def _get_channel_playlists(self, youtube: Any, channel_id: str) -> list[dict[str, Any]]:\n        \"\"\"Gets the public playlists for a channel.\"\"\"\n        try:\n            playlists_request = youtube.playlists().list(\n                part=\"snippet,contentDetails\",\n                channelId=channel_id,\n                maxResults=self.MAX_PLAYLIST_RESULTS,\n            )\n            playlists_response = playlists_request.execute()\n            playlists = []\n\n            for item in playlists_response.get(\"items\", []):\n                playlist_data = {\n                    \"playlist_title\": item[\"snippet\"][\"title\"],\n                    \"playlist_description\": item[\"snippet\"][\"description\"],\n                    \"playlist_id\": item[\"id\"],\n                    \"playlist_video_count\": item[\"contentDetails\"][\"itemCount\"],\n                    \"playlist_published_at\": item[\"snippet\"][\"publishedAt\"],\n                    \"playlist_thumbnail_url\": item[\"snippet\"][\"thumbnails\"][\"default\"][\"url\"],\n                }\n                playlists.append(playlist_data)\n\n            return playlists\n        except (HttpError, HTTPError) as e:\n            return [{\"error\": str(e)}]\n        else:\n            return playlists\n\n    def get_channel_info(self) -> DataFrame:\n        \"\"\"Retrieves channel information and returns it as a DataFrame.\"\"\"\n        youtube = None\n        try:\n            # Get channel ID and initialize YouTube API client\n            channel_id = self._extract_channel_id(self.channel_url)\n            youtube = build(\"youtube\", \"v3\", developerKey=self.api_key)\n\n            # Prepare parts for the API request\n            parts = [\"snippet\", \"contentDetails\"]\n            if self.include_statistics:\n                parts.append(\"statistics\")\n            if self.include_branding:\n                parts.append(\"brandingSettings\")\n\n            # Get channel information\n            channel_response = youtube.channels().list(part=\",\".join(parts), id=channel_id).execute()\n\n            if not channel_response[\"items\"]:\n                return DataFrame(pd.DataFrame({\"error\": [\"Channel not found\"]}))\n\n            channel_info = channel_response[\"items\"][0]\n\n            # Build basic channel data\n            channel_data = {\n                \"title\": [channel_info[\"snippet\"][\"title\"]],\n                \"description\": [channel_info[\"snippet\"][\"description\"]],\n                \"custom_url\": [channel_info[\"snippet\"].get(\"customUrl\", \"\")],\n                \"published_at\": [channel_info[\"snippet\"][\"publishedAt\"]],\n                \"country\": [channel_info[\"snippet\"].get(\"country\", \"Not specified\")],\n                \"channel_id\": [channel_id],\n            }\n\n            # Add thumbnails\n            for size, thumb in channel_info[\"snippet\"][\"thumbnails\"].items():\n                channel_data[f\"thumbnail_{size}\"] = [thumb[\"url\"]]\n\n            # Add statistics if requested\n            if self.include_statistics:\n                stats = channel_info[\"statistics\"]\n                channel_data.update(\n                    {\n                        \"view_count\": [int(stats.get(\"viewCount\", 0))],\n                        \"subscriber_count\": [int(stats.get(\"subscriberCount\", 0))],\n                        \"hidden_subscriber_count\": [stats.get(\"hiddenSubscriberCount\", False)],\n                        \"video_count\": [int(stats.get(\"videoCount\", 0))],\n                    }\n                )\n\n            # Add branding if requested\n            if self.include_branding:\n                branding = channel_info.get(\"brandingSettings\", {})\n                channel_data.update(\n                    {\n                        \"brand_title\": [branding.get(\"channel\", {}).get(\"title\", \"\")],\n                        \"brand_description\": [branding.get(\"channel\", {}).get(\"description\", \"\")],\n                        \"brand_keywords\": [branding.get(\"channel\", {}).get(\"keywords\", \"\")],\n                        \"brand_banner_url\": [branding.get(\"image\", {}).get(\"bannerExternalUrl\", \"\")],\n                    }\n                )\n\n            # Create the initial DataFrame\n            channel_df = pd.DataFrame(channel_data)\n\n            # Add playlists if requested\n            if self.include_playlists:\n                playlists = self._get_channel_playlists(youtube, channel_id)\n                if playlists and \"error\" not in playlists[0]:\n                    # Create a DataFrame for playlists\n                    playlists_df = pd.DataFrame(playlists)\n                    # Join with main DataFrame\n                    channel_df = pd.concat([channel_df] * len(playlists_df), ignore_index=True)\n                    for column in playlists_df.columns:\n                        channel_df[column] = playlists_df[column].to_numpy()\n\n            return DataFrame(channel_df)\n\n        except (HttpError, HTTPError, Exception) as e:\n            return DataFrame(pd.DataFrame({\"error\": [str(e)]}))\n        finally:\n            if youtube:\n                youtube.close()\n"
              },
              "include_branding": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Include Branding",
                "dynamic": false,
                "info": "Include channel branding settings (banner, thumbnails).",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_branding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "include_playlists": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Include Playlists",
                "dynamic": false,
                "info": "Include channel's public playlists.",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_playlists",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "include_statistics": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Include Statistics",
                "dynamic": false,
                "info": "Include channel statistics (views, subscribers, videos).",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_statistics",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "YouTubeChannelComponent"
        },
        "dragging": false,
        "id": "YouTubeChannelComponent-nVnTS",
        "measured": {
          "height": 459,
          "width": 320
        },
        "position": {
          "x": 2372.1077088318566,
          "y": 1935.2813285349748
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GoogleGenerativeAIModel-uStvr",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Google Generative AI.",
            "display_name": "Google Generative AI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_output_tokens",
              "model_name",
              "api_key",
              "top_p",
              "temperature",
              "n",
              "top_k",
              "tool_model_enabled"
            ],
            "frozen": false,
            "icon": "GoogleGenerativeAI",
            "key": "GoogleGenerativeAIModel",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00963430161181485,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Google API Key",
                "dynamic": false,
                "info": "The Google API Key to use for the Google Generative AI.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nimport requests\nfrom loguru import logger\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput, SliderInput\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.schema import dotdict\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_output_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=GOOGLE_GENERATIVE_AI_MODELS,\n            value=\"gemini-1.5-pro\",\n            refresh_button=True,\n            combobox=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n            required=True,\n            real_time_refresh=True,\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Tool Model Enabled\",\n            info=\"Whether to use the tool model.\",\n            value=False,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError as e:\n            msg = \"The 'langchain_google_genai' package is required to use the Google Generative AI model.\"\n            raise ImportError(msg) from e\n\n        google_api_key = self.api_key\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        return ChatGoogleGenerativeAI(\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key).get_secret_value(),\n        )\n\n    def get_models(self, tool_model_enabled: bool | None = None) -> list[str]:\n        try:\n            import google.generativeai as genai\n\n            genai.configure(api_key=self.api_key)\n            model_ids = [\n                model.name.replace(\"models/\", \"\")\n                for model in genai.list_models()\n                if \"generateContent\" in model.supported_generation_methods\n            ]\n            model_ids.sort(reverse=True)\n        except (ImportError, ValueError) as e:\n            logger.exception(f\"Error getting model names: {e}\")\n            model_ids = GOOGLE_GENERATIVE_AI_MODELS\n        if tool_model_enabled:\n            try:\n                from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n            except ImportError as e:\n                msg = \"langchain_google_genai is not installed.\"\n                raise ImportError(msg) from e\n            for model in model_ids:\n                model_with_tool = ChatGoogleGenerativeAI(\n                    model=self.model_name,\n                    google_api_key=self.api_key,\n                )\n                if not self.supports_tool_calling(model_with_tool):\n                    model_ids.remove(model)\n        return model_ids\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name in {\"base_url\", \"model_name\", \"tool_model_enabled\", \"api_key\"} and field_value:\n            try:\n                if len(self.api_key) == 0:\n                    ids = GOOGLE_GENERATIVE_AI_MODELS\n                else:\n                    try:\n                        ids = self.get_models(tool_model_enabled=self.tool_model_enabled)\n                    except (ImportError, ValueError, requests.exceptions.RequestException) as e:\n                        logger.exception(f\"Error getting model names: {e}\")\n                        ids = GOOGLE_GENERATIVE_AI_MODELS\n                build_config[\"model_name\"][\"options\"] = ids\n                build_config[\"model_name\"][\"value\"] = ids[0]\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_output_tokens": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Max Output Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_output_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "info": "The name of the model to use.",
                "name": "model_name",
                "options": [
                  "learnlm-1.5-pro-experimental",
                  "gemma-3-4b-it",
                  "gemma-3-27b-it",
                  "gemma-3-1b-it",
                  "gemma-3-12b-it",
                  "gemini-pro-vision",
                  "gemini-exp-1206",
                  "gemini-2.5-pro-preview-03-25",
                  "gemini-2.5-pro-exp-03-25",
                  "gemini-2.0-pro-exp-02-05",
                  "gemini-2.0-pro-exp",
                  "gemini-2.0-flash-thinking-exp-1219",
                  "gemini-2.0-flash-thinking-exp-01-21",
                  "gemini-2.0-flash-thinking-exp",
                  "gemini-2.0-flash-lite-preview-02-05",
                  "gemini-2.0-flash-lite-preview",
                  "gemini-2.0-flash-lite-001",
                  "gemini-2.0-flash-lite",
                  "gemini-2.0-flash-exp-image-generation",
                  "gemini-2.0-flash-exp",
                  "gemini-2.0-flash-001",
                  "gemini-2.0-flash",
                  "gemini-1.5-pro-latest",
                  "gemini-1.5-pro-002",
                  "gemini-1.5-pro-001",
                  "gemini-1.5-pro",
                  "gemini-1.5-flash-latest",
                  "gemini-1.5-flash-8b-latest",
                  "gemini-1.5-flash-8b-exp-0924",
                  "gemini-1.5-flash-8b-exp-0827",
                  "gemini-1.5-flash-8b-001",
                  "gemini-1.5-flash-8b",
                  "gemini-1.5-flash-002",
                  "gemini-1.5-flash-001-tuning",
                  "gemini-1.5-flash-001",
                  "gemini-1.5-flash",
                  "gemini-1.0-pro-vision-latest"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "learnlm-1.5-pro-experimental"
              },
              "n": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "N",
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Your objective is to ask to the user the Youtubeurs video link or the Youtube video Channel to give him so details using the next agent AI.\nYour output format is the link alone (nothing more than the link alone)."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Tool Model Enabled",
                "dynamic": false,
                "info": "Whether to use the tool model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "top_p": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Top P",
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_p",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "GoogleGenerativeAIModel"
        },
        "dragging": false,
        "id": "GoogleGenerativeAIModel-uStvr",
        "measured": {
          "height": 744,
          "width": 320
        },
        "position": {
          "x": 831.4802710053987,
          "y": 1121.0611904230668
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-ByYQm",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "outputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00012027401062119145,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-ByYQm",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": 2176.716369526808,
          "y": 2624.1297366415088
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "parser-ABlBu",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Format a DataFrame or Data object into text using a template. Enable 'Stringify' to convert input into a readable string instead.",
            "display_name": "Parser",
            "documentation": "",
            "edited": false,
            "field_order": [
              "mode",
              "pattern",
              "input_data",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "parser",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 2.220446049250313e-16,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Clean Data",
                "dynamic": false,
                "info": "Enable to clean the data by removing empty rows and lines in each cell of the DataFrame/ Data object.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TabInput,\n)\nfrom langflow.schema import Data, DataFrame\nfrom langflow.schema.message import Message\n\n\nclass ParserComponent(Component):\n    name = \"parser\"\n    display_name = \"Parser\"\n    description = (\n        \"Format a DataFrame or Data object into text using a template. \"\n        \"Enable 'Stringify' to convert input into a readable string instead.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                return json.dumps(data.data)\n            if isinstance(data, DataFrame):\n                if hasattr(self, \"clean_data\") and self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([self._safe_convert(item) for item in self.input_data])\n        else:\n            result = self._safe_convert(self.input_data)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Stringify"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{model_response}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "parser"
        },
        "dragging": false,
        "id": "parser-ABlBu",
        "measured": {
          "height": 314,
          "width": 320
        },
        "position": {
          "x": 2700.6700295042665,
          "y": 1936.0496421006458
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-goJvm",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "url",
                "stats"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "stats": {
                "advanced": false,
                "display_name": "stats",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "stats",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "\nVideo URL:\n{url}\n\nStatistics Analysis:\n{stats}"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "url": {
                "advanced": false,
                "display_name": "url",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-goJvm",
        "measured": {
          "height": 489,
          "width": 320
        },
        "position": {
          "x": 3029.487641766927,
          "y": 1936.9598836586897
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-sFwPn",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-sFwPn",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": 3888.845001627745,
          "y": 2430.1007141630694
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-eNA3t",
          "node": {
            "description": "**🧠🎥 Full YouTube Video Analysis – Step-by-Step**\n\nThis section performs an in-depth analysis of a YouTube video by combining multiple types of information:\n\n🔗 1. Video Link Input\nThe user provides a video URL.\n\n📊 2. Statistics Retrieval\nUsing the YouTube API, we collect key metrics: views, likes, comments, duration, etc.\n\n📄 3. Transcript Extraction\nThe video's transcript is retrieved and analyzed to identify main topics and structure.\n\n💬 4. Audience Sentiment (Optional)\nIf available, we summarize the emotional tone of viewer comments (positive, negative, sarcastic…).\n\n🤖 5. AI-Powered Report Generation\nAll the data (stats + content + sentiment) is sent to an AI model. It produces a comprehensive report including:\n\t•\tVideo performance\n\t•\tContent summary\n\t•\tAudience reaction\n\t•\tSynthesis & improvement suggestions\n\n✅ Ideal for creators, marketers, or researchers who want to understand how a video performs and resonates.",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "rose"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "id": "note-eNA3t",
        "measured": {
          "height": 789,
          "width": 326
        },
        "position": {
          "x": 1622.7346774526964,
          "y": 100.27662023499708
        },
        "selected": false,
        "type": "noteNode"
      },
      {
        "data": {
          "id": "note-dwC1c",
          "node": {
            "description": "**📈📺 YouTube Channel Analysis – Step-by-Step**\n\nThis section focuses on analyzing an entire YouTube channel by looking at aggregated data and patterns:\n\n🔗 1. Channel Link Input\nThe user provides a YouTube channel URL.\n\n📊 2. Channel Statistics Retrieval\nWe fetch key global stats via the YouTube API:\n\t•\tSubscriber count\n\t•\tTotal views\n\t•\tNumber of videos\n\t•\tAverage likes/comments/views\n\n🎯 3. Content Theme Detection\nBased on video titles and metadata, we identify recurring topics, formats, or trends.\n\n💬 4. Inferred Audience Sentiment\nSince we can't access all comments directly, we estimate the overall audience reaction using indirect signals:\n\t•\tLike-to-view ratio\n\t•\tComment activity\n\t•\tEngagement consistency\n\n🤖 5. AI Report Generation\nAll this info is sent to an AI model that produces a complete channel overview including:\n\t•\tPerformance summary\n\t•\tContent focus\n\t•\tInferred audience sentiment\n\t•\tStrategic recommendations for growth and engagement\n\n🚀 Perfect for creators who want to improve their channel, or analysts looking to assess content strategy at scale.",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "id": "note-dwC1c",
        "measured": {
          "height": 829,
          "width": 326
        },
        "position": {
          "x": 1617.0120777631523,
          "y": 1938.2077110075422
        },
        "selected": false,
        "type": "noteNode"
      },
      {
        "data": {
          "id": "GoogleGenerativeAIModel-N7NVN",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Google Generative AI.",
            "display_name": "Google Generative AI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_output_tokens",
              "model_name",
              "api_key",
              "top_p",
              "temperature",
              "n",
              "top_k",
              "tool_model_enabled"
            ],
            "frozen": false,
            "icon": "GoogleGenerativeAI",
            "key": "GoogleGenerativeAIModel",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00963430161181485,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Google API Key",
                "dynamic": false,
                "info": "The Google API Key to use for the Google Generative AI.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nimport requests\nfrom loguru import logger\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput, SliderInput\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.schema import dotdict\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_output_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=GOOGLE_GENERATIVE_AI_MODELS,\n            value=\"gemini-1.5-pro\",\n            refresh_button=True,\n            combobox=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n            required=True,\n            real_time_refresh=True,\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Tool Model Enabled\",\n            info=\"Whether to use the tool model.\",\n            value=False,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError as e:\n            msg = \"The 'langchain_google_genai' package is required to use the Google Generative AI model.\"\n            raise ImportError(msg) from e\n\n        google_api_key = self.api_key\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        return ChatGoogleGenerativeAI(\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key).get_secret_value(),\n        )\n\n    def get_models(self, tool_model_enabled: bool | None = None) -> list[str]:\n        try:\n            import google.generativeai as genai\n\n            genai.configure(api_key=self.api_key)\n            model_ids = [\n                model.name.replace(\"models/\", \"\")\n                for model in genai.list_models()\n                if \"generateContent\" in model.supported_generation_methods\n            ]\n            model_ids.sort(reverse=True)\n        except (ImportError, ValueError) as e:\n            logger.exception(f\"Error getting model names: {e}\")\n            model_ids = GOOGLE_GENERATIVE_AI_MODELS\n        if tool_model_enabled:\n            try:\n                from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n            except ImportError as e:\n                msg = \"langchain_google_genai is not installed.\"\n                raise ImportError(msg) from e\n            for model in model_ids:\n                model_with_tool = ChatGoogleGenerativeAI(\n                    model=self.model_name,\n                    google_api_key=self.api_key,\n                )\n                if not self.supports_tool_calling(model_with_tool):\n                    model_ids.remove(model)\n        return model_ids\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name in {\"base_url\", \"model_name\", \"tool_model_enabled\", \"api_key\"} and field_value:\n            try:\n                if len(self.api_key) == 0:\n                    ids = GOOGLE_GENERATIVE_AI_MODELS\n                else:\n                    try:\n                        ids = self.get_models(tool_model_enabled=self.tool_model_enabled)\n                    except (ImportError, ValueError, requests.exceptions.RequestException) as e:\n                        logger.exception(f\"Error getting model names: {e}\")\n                        ids = GOOGLE_GENERATIVE_AI_MODELS\n                build_config[\"model_name\"][\"options\"] = ids\n                build_config[\"model_name\"][\"value\"] = ids[0]\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_output_tokens": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Max Output Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_output_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10000
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "info": "The name of the model to use.",
                "name": "model_name",
                "options": [
                  "learnlm-1.5-pro-experimental",
                  "gemma-3-4b-it",
                  "gemma-3-27b-it",
                  "gemma-3-1b-it",
                  "gemma-3-12b-it",
                  "gemini-pro-vision",
                  "gemini-exp-1206",
                  "gemini-2.5-pro-preview-03-25",
                  "gemini-2.5-pro-exp-03-25",
                  "gemini-2.0-pro-exp-02-05",
                  "gemini-2.0-pro-exp",
                  "gemini-2.0-flash-thinking-exp-1219",
                  "gemini-2.0-flash-thinking-exp-01-21",
                  "gemini-2.0-flash-thinking-exp",
                  "gemini-2.0-flash-lite-preview-02-05",
                  "gemini-2.0-flash-lite-preview",
                  "gemini-2.0-flash-lite-001",
                  "gemini-2.0-flash-lite",
                  "gemini-2.0-flash-exp-image-generation",
                  "gemini-2.0-flash-exp",
                  "gemini-2.0-flash-001",
                  "gemini-2.0-flash",
                  "gemini-1.5-pro-latest",
                  "gemini-1.5-pro-002",
                  "gemini-1.5-pro-001",
                  "gemini-1.5-pro",
                  "gemini-1.5-flash-latest",
                  "gemini-1.5-flash-8b-latest",
                  "gemini-1.5-flash-8b-exp-0924",
                  "gemini-1.5-flash-8b-exp-0827",
                  "gemini-1.5-flash-8b-001",
                  "gemini-1.5-flash-8b",
                  "gemini-1.5-flash-002",
                  "gemini-1.5-flash-001-tuning",
                  "gemini-1.5-flash-001",
                  "gemini-1.5-flash",
                  "gemini-1.0-pro-vision-latest"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "learnlm-1.5-pro-experimental"
              },
              "n": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "N",
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a specialized assistant focused on comprehensive YouTube video analysis. Your main responsibilities are:\n\t1.\tAnalyze the video transcript to extract key themes, ideas, and structure.\n\t2.\tInterpret YouTube video statistics to assess performance and engagement.\n\t3.\tProcess sentiment analysis results from audience comments in structured XML format.\n\nYour goal is to synthesize these inputs to produce a complete and insightful overview of the video, including:\n\t•\tWhat the video is about (content)\n\t•\tHow the audience reacted (sentiment)\n\t•\tHow well the video performed (statistics)\n\nYou will receive the following inputs:\n\t•\tVideo transcript\n\t•\tVideo statistics (structured JSON or dictionary containing fields like views, likes, comments, duration, etc.)\n\t•\tSentiment analysis of comments in the format:\n<sentiment_analysis>\n  <concise_reasoning>\n    [Short analysis of comment tone and emotional indicators]\n  </concise_reasoning>\n  <sentiment_type>\n    Positive / Neutral / Negative / Mixed / Sarcastic\n  </sentiment_type>\n</sentiment_analysis>\n\nYour analysis should:\n\t•\tIdentify main themes and topics from the transcript.\n\t•\tInterpret audience sentiment patterns from the XML data.\n\t•\tAnalyze video performance based on the statistics (views, like ratio, comment ratio, etc.).\n\t•\tDetect any misalignment between content and audience reaction.\n\t•\tProvide recommendations for future improvements or optimizations.\n\nOutput format: Please output your analysis as a JSON object with the following keys:\n{\n  \"video_statistics\": \"Your analysis summary of key metrics and performance here\",\n  \"content_summary\": \"A concise summary of the video content, highlighting key ideas and structure.\",\n  \"audience_reception\": \"Your interpretation of audience sentiment based on the XML data.\",\n  \"synthesis\": \"A comparison of the video content versus audience reaction. Are they aligned? Any surprises?\",\n  \"recommendations\": [\n      \"Recommendation 1: description…\",\n      \"Recommendation 2: description…\",\n      ...\n  ]\n}\nPlease ensure that no extra text appears outside of this JSON format."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Tool Model Enabled",
                "dynamic": false,
                "info": "Whether to use the tool model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "top_p": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Top P",
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_p",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "GoogleGenerativeAIModel"
        },
        "dragging": false,
        "id": "GoogleGenerativeAIModel-N7NVN",
        "measured": {
          "height": 744,
          "width": 320
        },
        "position": {
          "x": 4495.840340346489,
          "y": 774.1068903137639
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CombineText-zsxGB",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "display_name": "Combine Text",
            "documentation": "",
            "edited": false,
            "field_order": [
              "text1",
              "text2",
              "delimiter"
            ],
            "frozen": false,
            "icon": "merge",
            "key": "CombineText",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined Text",
                "method": "combine_texts",
                "name": "combined_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n"
              },
              "delimiter": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Delimiter",
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "delimiter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " "
              },
              "text1": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "First Text",
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text1",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text2": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Second Text",
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text2",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CombineText"
        },
        "dragging": false,
        "id": "CombineText-zsxGB",
        "measured": {
          "height": 416,
          "width": 320
        },
        "position": {
          "x": 4163.6262887825105,
          "y": 774.4822902803554
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-umnnZ",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "url",
                "transcript"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "\nVideo URL:\n{url}\n\nTranscript:\n{transcript}"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "transcript": {
                "advanced": false,
                "display_name": "transcript",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "transcript",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "url": {
                "advanced": false,
                "display_name": "url",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-umnnZ",
        "measured": {
          "height": 489,
          "width": 320
        },
        "position": {
          "x": 3749.788727193129,
          "y": 437.6738685815945
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GoogleGenerativeAIModel-it4Oo",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Google Generative AI.",
            "display_name": "Google Generative AI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_output_tokens",
              "model_name",
              "api_key",
              "top_p",
              "temperature",
              "n",
              "top_k",
              "tool_model_enabled"
            ],
            "frozen": false,
            "icon": "GoogleGenerativeAI",
            "key": "GoogleGenerativeAIModel",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00963430161181485,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Google API Key",
                "dynamic": false,
                "info": "The Google API Key to use for the Google Generative AI.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nimport requests\nfrom loguru import logger\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput, SliderInput\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.schema import dotdict\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_output_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=GOOGLE_GENERATIVE_AI_MODELS,\n            value=\"gemini-1.5-pro\",\n            refresh_button=True,\n            combobox=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n            required=True,\n            real_time_refresh=True,\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Tool Model Enabled\",\n            info=\"Whether to use the tool model.\",\n            value=False,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError as e:\n            msg = \"The 'langchain_google_genai' package is required to use the Google Generative AI model.\"\n            raise ImportError(msg) from e\n\n        google_api_key = self.api_key\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        return ChatGoogleGenerativeAI(\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key).get_secret_value(),\n        )\n\n    def get_models(self, tool_model_enabled: bool | None = None) -> list[str]:\n        try:\n            import google.generativeai as genai\n\n            genai.configure(api_key=self.api_key)\n            model_ids = [\n                model.name.replace(\"models/\", \"\")\n                for model in genai.list_models()\n                if \"generateContent\" in model.supported_generation_methods\n            ]\n            model_ids.sort(reverse=True)\n        except (ImportError, ValueError) as e:\n            logger.exception(f\"Error getting model names: {e}\")\n            model_ids = GOOGLE_GENERATIVE_AI_MODELS\n        if tool_model_enabled:\n            try:\n                from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n            except ImportError as e:\n                msg = \"langchain_google_genai is not installed.\"\n                raise ImportError(msg) from e\n            for model in model_ids:\n                model_with_tool = ChatGoogleGenerativeAI(\n                    model=self.model_name,\n                    google_api_key=self.api_key,\n                )\n                if not self.supports_tool_calling(model_with_tool):\n                    model_ids.remove(model)\n        return model_ids\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name in {\"base_url\", \"model_name\", \"tool_model_enabled\", \"api_key\"} and field_value:\n            try:\n                if len(self.api_key) == 0:\n                    ids = GOOGLE_GENERATIVE_AI_MODELS\n                else:\n                    try:\n                        ids = self.get_models(tool_model_enabled=self.tool_model_enabled)\n                    except (ImportError, ValueError, requests.exceptions.RequestException) as e:\n                        logger.exception(f\"Error getting model names: {e}\")\n                        ids = GOOGLE_GENERATIVE_AI_MODELS\n                build_config[\"model_name\"][\"options\"] = ids\n                build_config[\"model_name\"][\"value\"] = ids[0]\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_output_tokens": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Max Output Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_output_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10000
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "info": "The name of the model to use.",
                "name": "model_name",
                "options": [
                  "learnlm-1.5-pro-experimental",
                  "gemma-3-4b-it",
                  "gemma-3-27b-it",
                  "gemma-3-1b-it",
                  "gemma-3-12b-it",
                  "gemini-pro-vision",
                  "gemini-exp-1206",
                  "gemini-2.5-pro-preview-03-25",
                  "gemini-2.5-pro-exp-03-25",
                  "gemini-2.0-pro-exp-02-05",
                  "gemini-2.0-pro-exp",
                  "gemini-2.0-flash-thinking-exp-1219",
                  "gemini-2.0-flash-thinking-exp-01-21",
                  "gemini-2.0-flash-thinking-exp",
                  "gemini-2.0-flash-lite-preview-02-05",
                  "gemini-2.0-flash-lite-preview",
                  "gemini-2.0-flash-lite-001",
                  "gemini-2.0-flash-lite",
                  "gemini-2.0-flash-exp-image-generation",
                  "gemini-2.0-flash-exp",
                  "gemini-2.0-flash-001",
                  "gemini-2.0-flash",
                  "gemini-1.5-pro-latest",
                  "gemini-1.5-pro-002",
                  "gemini-1.5-pro-001",
                  "gemini-1.5-pro",
                  "gemini-1.5-flash-latest",
                  "gemini-1.5-flash-8b-latest",
                  "gemini-1.5-flash-8b-exp-0924",
                  "gemini-1.5-flash-8b-exp-0827",
                  "gemini-1.5-flash-8b-001",
                  "gemini-1.5-flash-8b",
                  "gemini-1.5-flash-002",
                  "gemini-1.5-flash-001-tuning",
                  "gemini-1.5-flash-001",
                  "gemini-1.5-flash",
                  "gemini-1.0-pro-vision-latest"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "learnlm-1.5-pro-experimental"
              },
              "n": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "N",
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a specialized assistant focused on comprehensive YouTube channel analysis.\n\nYour main responsibilities are:\n\t1.\tAnalyze aggregated video statistics across a channel to evaluate overall performance and trends.\n\t2.\tInfer audience sentiment and engagement quality using video-level statistics (e.g., like ratio, comment ratio, viewer interaction).\n\t3.\tIdentify recurring content themes based on available video titles, categories, or summaries.\n\nYour goal is to synthesize these inputs to provide a complete and insightful overview of the channel, including:\n\t•\tThe type of content produced and dominant themes\n\t•\tHow the audience likely reacts to the content (based on engagement indicators)\n\t•\tHow the channel performs in terms of reach, consistency, and growth\n\nYou will receive the following inputs:\n\t•\tChannel-level statistics (structured JSON or dictionary format with fields such as total views, subscriber count, total videos, average likes/views/comments, etc.)\n\nYour analysis should:\n\t•\tIdentify common content themes or video formats across the channel\n\t•\tInfer audience reception and emotional engagement from indirect signals (likes, comments, engagement rates)\n\t•\tEvaluate channel visibility, performance trends, and growth trajectory\n\t•\tHighlight any mismatch between content output and audience behavior\n\t•\tOffer actionable suggestions for increasing growth and engagement\n\nOutput format: Please output your analysis as a JSON object with the following keys:\n{\n   \"channel_statistics\": \"Your analysis here\",\n   \"content_themes\": \"Your analysis here\",\n   \"audience_reception\": \"Your analysis here\",\n   \"synthesis\": \"Your analysis here\",\n   \"recommendations\": [\n      \"Recommendation 1: description...\",\n      \"Recommendation 2: description...\",\n      ... etc.\n   ]\n}\nPlease make sure each field is a plain text string (or, for recommendations, a list of strings), and do not include any additional text."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Tool Model Enabled",
                "dynamic": false,
                "info": "Whether to use the tool model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "top_p": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Top P",
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_p",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "GoogleGenerativeAIModel"
        },
        "dragging": false,
        "id": "GoogleGenerativeAIModel-it4Oo",
        "measured": {
          "height": 744,
          "width": 320
        },
        "position": {
          "x": 3357.7708337744957,
          "y": 1937.6243850905626
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CombineText-7WtZf",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "display_name": "Combine Text",
            "documentation": "",
            "edited": false,
            "field_order": [
              "text1",
              "text2",
              "delimiter"
            ],
            "frozen": false,
            "icon": "merge",
            "key": "CombineText",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined Text",
                "method": "combine_texts",
                "name": "combined_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n"
              },
              "delimiter": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Delimiter",
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "delimiter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " |||"
              },
              "text1": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "First Text",
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text1",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text2": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Second Text",
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text2",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CombineText"
        },
        "dragging": false,
        "id": "CombineText-7WtZf",
        "measured": {
          "height": 416,
          "width": 320
        },
        "position": {
          "x": 4830.132752289432,
          "y": 776.0999213045123
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CombineText-6WywH",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "display_name": "Combine Text",
            "documentation": "",
            "edited": false,
            "field_order": [
              "text1",
              "text2",
              "delimiter"
            ],
            "frozen": false,
            "icon": "merge",
            "key": "CombineText",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined Text",
                "method": "combine_texts",
                "name": "combined_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n"
              },
              "delimiter": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Delimiter",
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "delimiter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": " |||"
              },
              "text1": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "First Text",
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text1",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "text2": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Second Text",
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text2",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CombineText"
        },
        "dragging": false,
        "id": "CombineText-6WywH",
        "measured": {
          "height": 416,
          "width": 320
        },
        "position": {
          "x": 3686.731662324481,
          "y": 1938.3400764465707
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-pSsME",
          "node": {
            "description": "**🔑 Complete with your API KEY**\n\n\n\n- YouTube Data API v3 key 📹\n\n- Gemini API key ✨\n\n",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-pSsME",
        "measured": {
          "height": 324,
          "width": 326
        },
        "position": {
          "x": 631.4017057948746,
          "y": 665.8099828423263
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 324
      }
    ],
    "viewport": {
      "x": -59.42435373235992,
      "y": 87.82303581148005,
      "zoom": 0.2720002467462173
    }
  },
  "description": "The YouTube Details extracts video or channel information, and provides it to the user.",
  "endpoint_name": null,
  "folder_id": "37dbd39d-882e-44dc-89d5-ef9e68b4c9a8",
  "fs_path": null,
  "gradient": null,
  "icon": null,
  "icon_bg_color": null,
  "id": "39defa02-2bf4-4644-ab2c-d3b7c13b8481",
  "is_component": false,
  "locked": false,
  "name": "youtube-intelligence-flow",
  "tags": [],
  "updated_at": "2025-04-11T22:06:01+00:00",
  "user_id": "6e5f43a9-0a83-4cc8-816b-252cfea773e9",
  "webhook": false
}